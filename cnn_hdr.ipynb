{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcf5e74b-3b44-4b75-8357-b00e9b050edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba677718-b54f-46d8-bcef-38c455605b84",
   "metadata": {},
   "source": [
    "This time you will define a large CNN architecture with additional convolutional, max pooling layers, and fully connected layers. The network topology can be summarized as follows:\n",
    "\n",
    "Convolutional layer with 30 feature maps of size 5×5\n",
    "Pooling layer taking the max over 2*2 patches\n",
    "Convolutional layer with 15 feature maps of size 3×3\n",
    "Pooling layer taking the max over 2*2 patches\n",
    "Dropout layer with a probability of 20%\n",
    "Flatten layer\n",
    "Fully connected layer with 128 neurons and rectifier activation\n",
    "Fully connected layer with 50 neurons and rectifier activation\n",
    "Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cd98793-b5ca-4c9a-80df-64be6fb92c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def larger_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " model.add(Dropout(0.2))\n",
    " model.add(Flatten())\n",
    " model.add(Dense(128, activation='relu'))\n",
    " model.add(Dense(50, activation='relu'))\n",
    " model.add(Dense(num_classes, activation='softmax'))\n",
    " # Compile model\n",
    " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4a200d0-3960-4f08-b2ce-2c12260cfc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7623 - loss: 0.7904 - val_accuracy: 0.9771 - val_loss: 0.0730\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9684 - loss: 0.1026 - val_accuracy: 0.9844 - val_loss: 0.0492\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9798 - loss: 0.0669 - val_accuracy: 0.9864 - val_loss: 0.0431\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9827 - loss: 0.0571 - val_accuracy: 0.9885 - val_loss: 0.0346\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9849 - loss: 0.0478 - val_accuracy: 0.9902 - val_loss: 0.0319\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9859 - loss: 0.0431 - val_accuracy: 0.9898 - val_loss: 0.0333\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9885 - loss: 0.0370 - val_accuracy: 0.9913 - val_loss: 0.0287\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9907 - loss: 0.0311 - val_accuracy: 0.9903 - val_loss: 0.0283\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9905 - loss: 0.0307 - val_accuracy: 0.9918 - val_loss: 0.0266\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9906 - loss: 0.0271 - val_accuracy: 0.9924 - val_loss: 0.0248\n",
      "Large CNN Error: 0.76%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f27afca-5a8a-4db0-a865-5364de15793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.024842597544193268, 0.9923999905586243]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d25ada01-4911-4a5e-9e0c-a851e5c13a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('digit_recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b00f3b-ad02-463b-877c-284558700383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
